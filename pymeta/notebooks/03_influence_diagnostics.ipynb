{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Influence Diagnostics in Meta-Analysis\n",
    "\n",
    "This notebook demonstrates advanced influence diagnostics and outlier detection methods in PyMeta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pymeta as pm\n",
    "from scipy import stats\n",
    "\n",
    "plt.style.use('seaborn-v0_8')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Data with Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample data with some outlying studies\n",
    "np.random.seed(123)\n",
    "\n",
    "n_studies = 20\n",
    "studies = [f'Study_{i+1:02d}' for i in range(n_studies)]\n",
    "\n",
    "# Generate effect sizes - most studies around 0.3, but some outliers\n",
    "effect_sizes = np.random.normal(0.3, 0.1, n_studies)\n",
    "\n",
    "# Add some outliers\n",
    "outlier_indices = [5, 12, 17]\n",
    "effect_sizes[outlier_indices] = [0.8, -0.2, 1.1]  # Clear outliers\n",
    "\n",
    "# Generate variances (inversely related to sample size)\n",
    "sample_sizes = np.random.randint(50, 300, n_studies)\n",
    "variances = (2.0 / np.sqrt(sample_sizes)) * np.random.uniform(0.8, 1.2, n_studies)\n",
    "\n",
    "# One study with very large variance (poor quality)\n",
    "variances[8] = 0.15\n",
    "\n",
    "data = pd.DataFrame({\n",
    "    'study': studies,\n",
    "    'effect_size': effect_sizes,\n",
    "    'variance': variances,\n",
    "    'standard_error': np.sqrt(variances),\n",
    "    'sample_size': sample_sizes,\n",
    "    'year': np.random.randint(2010, 2024, n_studies),\n",
    "    'quality': np.random.choice(['High', 'Medium', 'Low'], n_studies)\n",
    "})\n",
    "\n",
    "print(f\"Created dataset with {len(data)} studies\")\n",
    "print(f\"Outlier studies: {[studies[i] for i in outlier_indices]}\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Meta-Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform initial meta-analysis\n",
    "result = pm.meta_analysis(data, model='random', tau2_method='reml')\n",
    "\n",
    "print(\"Initial Meta-Analysis Results:\")\n",
    "print(\"-\" * 35)\n",
    "print(f\"Overall effect: {result.overall_effect:.3f}\")\n",
    "print(f\"95% CI: [{result.ci_lower:.3f}, {result.ci_upper:.3f}]\")\n",
    "print(f\"Tau²: {result.tau_squared:.3f}\")\n",
    "print(f\"I²: {result.i_squared:.1f}%\")\n",
    "print(f\"Q-statistic: {result.q_statistic:.2f} (p = {result.q_pvalue:.3f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial forest plot\n",
    "fig, ax = plt.subplots(figsize=(12, 10))\n",
    "pm.forest_plot(result, ax=ax, title='Forest Plot - All Studies')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Leave-One-Out Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leave-one-out influence analysis\n",
    "loo_result = pm.leave_one_out(data)\n",
    "\n",
    "print(\"Leave-One-Out Analysis:\")\n",
    "print(\"-\" * 25)\n",
    "print(f\"Effect size range: {loo_result.min_effect:.3f} to {loo_result.max_effect:.3f}\")\n",
    "print(f\"Standard error range: {loo_result.min_se:.3f} to {loo_result.max_se:.3f}\")\n",
    "print(f\"Most influential study: {loo_result.most_influential_study}\")\n",
    "print(f\"Maximum influence: {loo_result.max_influence:.3f}\")\n",
    "\n",
    "# Display top 5 most influential studies\n",
    "print(\"\\nTop 5 Most Influential Studies:\")\n",
    "influence_df = loo_result.influence_data.sort_values('influence', ascending=False).head()\n",
    "for _, row in influence_df.iterrows():\n",
    "    print(f\"  {row['study']}: Influence = {row['influence']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize leave-one-out results\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Influence plot\n",
    "pm.influence_plot(loo_result, ax=axes[0,0], title='Leave-One-Out Influence')\n",
    "\n",
    "# Effect size change plot\n",
    "pm.loo_effect_plot(loo_result, ax=axes[0,1], title='Effect Size Changes')\n",
    "\n",
    "# Standard error change plot\n",
    "pm.loo_se_plot(loo_result, ax=axes[1,0], title='Standard Error Changes')\n",
    "\n",
    "# Combined influence metrics\n",
    "pm.influence_metrics_plot(loo_result, ax=axes[1,1], title='Multiple Influence Metrics')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Studentized Residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate studentized residuals\n",
    "residuals_result = pm.studentized_residuals(data)\n",
    "\n",
    "print(\"Studentized Residuals Analysis:\")\n",
    "print(\"-\" * 32)\n",
    "print(f\"Mean residual: {residuals_result.residuals.mean():.3f}\")\n",
    "print(f\"SD of residuals: {residuals_result.residuals.std():.3f}\")\n",
    "\n",
    "# Identify outliers (|residual| > 2 or 3)\n",
    "moderate_outliers = residuals_result.outliers_moderate  # |residual| > 2\n",
    "extreme_outliers = residuals_result.outliers_extreme    # |residual| > 3\n",
    "\n",
    "print(f\"\\nModerate outliers (|residual| > 2): {len(moderate_outliers)}\")\n",
    "for study in moderate_outliers:\n",
    "    idx = data[data['study'] == study].index[0]\n",
    "    residual = residuals_result.residuals.iloc[idx]\n",
    "    print(f\"  {study}: {residual:.3f}\")\n",
    "\n",
    "print(f\"\\nExtreme outliers (|residual| > 3): {len(extreme_outliers)}\")\n",
    "for study in extreme_outliers:\n",
    "    idx = data[data['study'] == study].index[0]\n",
    "    residual = residuals_result.residuals.iloc[idx]\n",
    "    print(f\"  {study}: {residual:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize residuals\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "# Residuals vs fitted values\n",
    "pm.residual_plot(residuals_result, ax=axes[0,0], title='Residuals vs Fitted')\n",
    "\n",
    "# Q-Q plot of residuals\n",
    "pm.qq_plot(residuals_result, ax=axes[0,1], title='Q-Q Plot of Residuals')\n",
    "\n",
    "# Histogram of residuals\n",
    "axes[1,0].hist(residuals_result.residuals, bins=10, alpha=0.7, edgecolor='black')\n",
    "axes[1,0].axvline(0, color='red', linestyle='--', alpha=0.7)\n",
    "axes[1,0].axvline(2, color='orange', linestyle='--', alpha=0.7, label='Moderate outlier')\n",
    "axes[1,0].axvline(-2, color='orange', linestyle='--', alpha=0.7)\n",
    "axes[1,0].axvline(3, color='red', linestyle='--', alpha=0.7, label='Extreme outlier')\n",
    "axes[1,0].axvline(-3, color='red', linestyle='--', alpha=0.7)\n",
    "axes[1,0].set_xlabel('Studentized Residual')\n",
    "axes[1,0].set_ylabel('Frequency')\n",
    "axes[1,0].set_title('Distribution of Residuals')\n",
    "axes[1,0].legend()\n",
    "\n",
    "# Residuals vs precision\n",
    "pm.residual_precision_plot(residuals_result, ax=axes[1,1], title='Residuals vs Precision')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Baujat Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baujat analysis - identifies studies contributing to heterogeneity\n",
    "baujat_result = pm.baujat_analysis(data)\n",
    "\n",
    "print(\"Baujat Analysis:\")\n",
    "print(\"-\" * 16)\n",
    "print(\"Studies with high contribution to heterogeneity:\")\n",
    "\n",
    "# Identify studies in upper right quadrant\n",
    "high_contrib = baujat_result.high_heterogeneity_contribution\n",
    "for study in high_contrib:\n",
    "    idx = data[data['study'] == study].index[0]\n",
    "    contrib = baujat_result.heterogeneity_contribution.iloc[idx]\n",
    "    influence = baujat_result.overall_influence.iloc[idx]\n",
    "    print(f\"  {study}: H² contribution = {contrib:.3f}, Influence = {influence:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baujat plot with study labels\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "pm.baujat_plot(result, ax=ax, show_labels=True, title='Baujat Plot with Study Labels')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Cook's Distance and DFBETAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Cook's distance and DFBETAS\n",
    "influence_stats = pm.influence_statistics(data)\n",
    "\n",
    "print(\"Influence Statistics:\")\n",
    "print(\"-\" * 20)\n",
    "\n",
    "# Cook's Distance threshold (typically > 4/n)\n",
    "cooks_threshold = 4 / len(data)\n",
    "high_cooks = influence_stats.cooks_distance > cooks_threshold\n",
    "\n",
    "print(f\"Cook's Distance threshold: {cooks_threshold:.3f}\")\n",
    "print(f\"Studies with high Cook's Distance:\")\n",
    "for i, study in enumerate(data['study'][high_cooks]):\n",
    "    cooks_d = influence_stats.cooks_distance.iloc[i]\n",
    "    print(f\"  {study}: {cooks_d:.3f}\")\n",
    "\n",
    "# DFBETAS threshold (typically > 2/sqrt(n))\n",
    "dfbetas_threshold = 2 / np.sqrt(len(data))\n",
    "high_dfbetas = np.abs(influence_stats.dfbetas) > dfbetas_threshold\n",
    "\n",
    "print(f\"\\nDFBETAS threshold: ±{dfbetas_threshold:.3f}\")\n",
    "print(f\"Studies with high DFBETAS:\")\n",
    "for i, study in enumerate(data['study'][high_dfbetas]):\n",
    "    dfbetas = influence_stats.dfbetas.iloc[i]\n",
    "    print(f\"  {study}: {dfbetas:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize influence statistics\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "# Cook's Distance\n",
    "pm.cooks_distance_plot(influence_stats, ax=axes[0,0], title=\"Cook's Distance\")\n",
    "\n",
    "# DFBETAS\n",
    "pm.dfbetas_plot(influence_stats, ax=axes[0,1], title='DFBETAS')\n",
    "\n",
    "# Leverage vs Residuals\n",
    "pm.leverage_residual_plot(influence_stats, ax=axes[1,0], title='Leverage vs Residuals')\n",
    "\n",
    "# Influence bubble plot\n",
    "pm.influence_bubble_plot(influence_stats, ax=axes[1,1], title='Influence Bubble Plot')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Outlier Detection Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive outlier detection\n",
    "outlier_summary = pm.outlier_detection_summary(data)\n",
    "\n",
    "print(\"Comprehensive Outlier Detection Summary:\")\n",
    "print(\"=\" * 42)\n",
    "\n",
    "outlier_df = outlier_summary.summary_table\n",
    "print(outlier_df.to_string())\n",
    "\n",
    "# Consensus outliers (flagged by multiple methods)\n",
    "consensus_outliers = outlier_summary.consensus_outliers\n",
    "print(f\"\\nConsensus outliers (flagged by ≥3 methods): {len(consensus_outliers)}\")\n",
    "for study in consensus_outliers:\n",
    "    methods = outlier_df.loc[outlier_df['study'] == study, 'methods_flagged'].iloc[0]\n",
    "    print(f\"  {study}: {methods} methods\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Sensitivity Analysis: Removing Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare results with and without outliers\n",
    "print(\"Sensitivity Analysis: Impact of Outlier Removal\")\n",
    "print(\"=\" * 48)\n",
    "\n",
    "# Original analysis\n",
    "original_result = pm.meta_analysis(data, model='random')\n",
    "print(f\"Original analysis (n={len(data)}):\")\n",
    "print(f\"  Effect: {original_result.overall_effect:.3f} [{original_result.ci_lower:.3f}, {original_result.ci_upper:.3f}]\")\n",
    "print(f\"  Tau²: {original_result.tau_squared:.3f}, I²: {original_result.i_squared:.1f}%\")\n",
    "\n",
    "# Remove consensus outliers\n",
    "if len(consensus_outliers) > 0:\n",
    "    data_no_outliers = data[~data['study'].isin(consensus_outliers)].copy()\n",
    "    \n",
    "    outlier_removed_result = pm.meta_analysis(data_no_outliers, model='random')\n",
    "    print(f\"\\nOutliers removed (n={len(data_no_outliers)}):\")\n",
    "    print(f\"  Effect: {outlier_removed_result.overall_effect:.3f} [{outlier_removed_result.ci_lower:.3f}, {outlier_removed_result.ci_upper:.3f}]\")\n",
    "    print(f\"  Tau²: {outlier_removed_result.tau_squared:.3f}, I²: {outlier_removed_result.i_squared:.1f}%\")\n",
    "    \n",
    "    # Calculate impact\n",
    "    effect_change = abs(outlier_removed_result.overall_effect - original_result.overall_effect)\n",
    "    tau2_change = abs(outlier_removed_result.tau_squared - original_result.tau_squared)\n",
    "    \n",
    "    print(f\"\\nImpact of outlier removal:\")\n",
    "    print(f\"  Effect size change: {effect_change:.3f}\")\n",
    "    print(f\"  Tau² change: {tau2_change:.3f}\")\n",
    "    print(f\"  I² change: {outlier_removed_result.i_squared - original_result.i_squared:.1f} percentage points\")\n",
    "else:\n",
    "    print(\"\\nNo consensus outliers identified.\")\n",
    "    data_no_outliers = data.copy()\n",
    "    outlier_removed_result = original_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Side-by-side forest plots\n",
    "fig, axes = plt.subplots(1, 2, figsize=(20, 10))\n",
    "\n",
    "# Original data\n",
    "pm.forest_plot(original_result, ax=axes[0], title=f'All Studies (n={len(data)})')\n",
    "\n",
    "# Without outliers\n",
    "pm.forest_plot(outlier_removed_result, ax=axes[1], title=f'Outliers Removed (n={len(data_no_outliers)})')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Advanced Influence Diagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advanced diagnostics\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Hat values (leverage)\n",
    "pm.leverage_plot(influence_stats, ax=axes[0,0], title='Leverage (Hat Values)')\n",
    "\n",
    "# Standardized residuals vs leverage\n",
    "pm.standard_residual_leverage_plot(influence_stats, ax=axes[0,1], \n",
    "                                  title='Standardized Residuals vs Leverage')\n",
    "\n",
    "# DFFITS\n",
    "pm.dffits_plot(influence_stats, ax=axes[1,0], title='DFFITS')\n",
    "\n",
    "# Covariance ratio\n",
    "pm.covariance_ratio_plot(influence_stats, ax=axes[1,1], title='Covariance Ratio')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Influence on Heterogeneity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine influence on heterogeneity measures\n",
    "het_influence = pm.heterogeneity_influence(data)\n",
    "\n",
    "print(\"Influence on Heterogeneity Measures:\")\n",
    "print(\"-\" * 36)\n",
    "print(f\"Original I²: {original_result.i_squared:.1f}%\")\n",
    "print(f\"Original Tau²: {original_result.tau_squared:.3f}\")\n",
    "print(f\"Original Q: {original_result.q_statistic:.2f}\")\n",
    "print()\n",
    "\n",
    "print(\"Studies with largest impact on heterogeneity:\")\n",
    "top_het_influence = het_influence.sort_values('tau2_change', ascending=False).head(5)\n",
    "for _, row in top_het_influence.iterrows():\n",
    "    print(f\"  {row['study']}: ΔTau² = {row['tau2_change']:.3f}, ΔI² = {row['i2_change']:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot heterogeneity influence\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "pm.tau2_influence_plot(het_influence, ax=axes[0], title='Influence on Tau²')\n",
    "pm.i2_influence_plot(het_influence, ax=axes[1], title='Influence on I²')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions and Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary of Influence Diagnostics\n",
    "\n",
    "This notebook demonstrated comprehensive influence diagnostics for meta-analysis:\n",
    "\n",
    "1. **Leave-One-Out Analysis** - Systematic removal of each study\n",
    "2. **Studentized Residuals** - Standardized measures of study deviation\n",
    "3. **Baujat Analysis** - Identification of heterogeneity contributors\n",
    "4. **Cook's Distance & DFBETAS** - Overall influence measures\n",
    "5. **Comprehensive Outlier Detection** - Multiple method consensus\n",
    "6. **Sensitivity Analysis** - Impact assessment of outlier removal\n",
    "7. **Advanced Diagnostics** - Leverage, DFFITS, covariance ratios\n",
    "8. **Heterogeneity Influence** - Impact on between-study variance\n",
    "\n",
    "### Key Findings:\n",
    "- Multiple outlying studies were detected across different methods\n",
    "- Consensus outliers significantly impact both effect size and heterogeneity\n",
    "- Removal of outliers leads to more precise estimates with reduced heterogeneity\n",
    "\n",
    "### Recommendations:\n",
    "1. Always conduct influence diagnostics in meta-analysis\n",
    "2. Use multiple detection methods for robust identification\n",
    "3. Investigate reasons for outlying results before removal\n",
    "4. Report sensitivity analyses with and without influential studies\n",
    "5. Consider subgroup analysis if outliers share characteristics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}